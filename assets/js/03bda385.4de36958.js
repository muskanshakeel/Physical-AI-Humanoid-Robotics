"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[9343],{903:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>r,default:()=>h,frontMatter:()=>s,metadata:()=>a,toc:()=>l});const a=JSON.parse('{"id":"module3/chapter3-implementation","title":"Module 3: The AI-Robot Brain (NVIDIA Isaac) - Chapter 3: Implementation Walkthrough","description":"1. Concepts","source":"@site/docs/module3/chapter3-implementation.md","sourceDirName":"module3","slug":"/module3/chapter3-implementation","permalink":"/Physical-AI-Humanoid-Robotics/docs/module3/chapter3-implementation","draft":false,"unlisted":false,"editUrl":"https://github.com/muskanshakeel/Physical-AI-Humanoid-Robotics/tree/main/my-website/docs/module3/chapter3-implementation.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Module 3: The AI-Robot Brain (NVIDIA Isaac) - Chapter 2: Tooling","permalink":"/Physical-AI-Humanoid-Robotics/docs/module3/chapter2-tooling"},"next":{"title":"Module 3: The AI-Robot Brain (NVIDIA Isaac) - Chapter 4: Case Study / Example","permalink":"/Physical-AI-Humanoid-Robotics/docs/module3/chapter4-casestudy"}}');var i=t(4848),o=t(8453);const s={sidebar_position:3},r="Module 3: The AI-Robot Brain (NVIDIA Isaac) - Chapter 3: Implementation Walkthrough",c={},l=[{value:"1. Concepts",id:"1-concepts",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",p:"p",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"module-3-the-ai-robot-brain-nvidia-isaac---chapter-3-implementation-walkthrough",children:"Module 3: The AI-Robot Brain (NVIDIA Isaac) - Chapter 3: Implementation Walkthrough"})}),"\n",(0,i.jsx)(n.h2,{id:"1-concepts",children:"1. Concepts"}),"\n",(0,i.jsx)(n.p,{children:"This chapter provides a practical walkthrough of setting up and running a Visual Simultaneous Localization and Mapping (VSLAM) pipeline using Isaac ROS. VSLAM is a crucial component for autonomous robots to understand their environment and navigate within it."}),"\n",(0,i.jsx)("h2",{children:" 2. Tooling"}),"\n",(0,i.jsx)(n.p,{children:"We will utilize NVIDIA Isaac Sim (for a simulated environment), Isaac ROS VSLAM package, a ROS 2 workspace, and an NVIDIA Jetson Orin device (or a powerful workstation with an NVIDIA GPU)."}),"\n",(0,i.jsx)("h2",{children:" 3. Implementation Walkthrough: Isaac ROS VSLAM on Jetson"}),"\n",(0,i.jsx)(n.p,{children:"This section provides a detailed walkthrough to implement a VSLAM pipeline using Isaac ROS, targeting an NVIDIA Jetson Orin device."}),"\n",(0,i.jsx)("h3",{children:" Step 1: Environment Setup"}),"\n",(0,i.jsx)(n.p,{children:"Ensure your Jetson Orin (or workstation) has Isaac ROS and ROS 2 Humble/Iron installed and configured."}),"\n",(0,i.jsx)("h3",{children:" Step 2: Launch Isaac Sim"}),"\n",(0,i.jsx)(n.p,{children:"Instructions on launching Isaac Sim with a suitable environment and a robot equipped with a camera."}),"\n",(0,i.jsx)("h3",{children:" Step 3: Run Isaac ROS VSLAM Node"}),"\n",(0,i.jsx)(n.p,{children:"Commands and configuration for launching the Isaac ROS VSLAM node, which processes camera images and generates pose estimates and a map."}),"\n",(0,i.jsx)("h3",{children:" Step 4: Visualize Results"}),"\n",(0,i.jsxs)(n.p,{children:["Using ",(0,i.jsx)(n.code,{children:"rviz"})," to visualize the robot's estimated trajectory and the generated map."]}),"\n",(0,i.jsx)("h2",{children:" 4. Case study / example"}),"\n",(0,i.jsx)(n.p,{children:"A case study on using the VSLAM output (pose estimates) to stabilize a drone's flight in a simulated environment."}),"\n",(0,i.jsx)("h2",{children:" 5. Mini project"}),"\n",(0,i.jsx)(n.p,{children:"A hands-on project to compare the performance and accuracy of Isaac ROS VSLAM against a CPU-based VSLAM solution in the same simulated environment."}),"\n",(0,i.jsx)("h2",{children:" 6. Debugging & common failures"}),"\n",(0,i.jsx)(n.p,{children:"Common issues encountered during VSLAM implementation, such as poor pose estimates, map drift, camera calibration errors, or performance limitations on the Jetson."})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>r});var a=t(6540);const i={},o=a.createContext(i);function s(e){const n=a.useContext(o);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),a.createElement(o.Provider,{value:n},e.children)}}}]);